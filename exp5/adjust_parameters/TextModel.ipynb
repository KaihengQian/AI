{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 实验准备"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a902fcebdc223667"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import BertModel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:55.545297600Z",
     "start_time": "2024-01-23T13:01:49.316289400Z"
    }
   },
   "id": "fd45712d8471b68a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:56.054402700Z",
     "start_time": "2024-01-23T13:01:55.549298400Z"
    }
   },
   "id": "e6f7dc16011be58a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果计算机安装有CUDA，则使用CUDA进行接下来的全部训练，否则使用CPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd586d9a675d3c72"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 如果计算机安装有CUDA，则使用CUDA进行接下来的全部训练，否则使用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:56.106414Z",
     "start_time": "2024-01-23T13:01:56.053402400Z"
    }
   },
   "id": "652fc857b3e56842"
  },
  {
   "cell_type": "markdown",
   "source": [
    "根据训练数据查看文本的长度分布"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b771f8745533f1e6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_path = '../dataset/train.txt'\n",
    "text_path = '../dataset/data/'\n",
    "\n",
    "train_df = pd.read_csv(train_set_path, index_col=False)\n",
    "guids = train_df['guid'].values\n",
    "\n",
    "train_text = []\n",
    "train_text_len = []\n",
    "\n",
    "for guid in guids:\n",
    "    path = text_path + str(guid) + '.txt'\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = [line.strip() for line in f.readlines() if line.strip()]  # 去除空行\n",
    "    text = ' '.join(text)\n",
    "        \n",
    "    tokens = word_tokenize(text)  # 分词\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # 去除标点符号和数字\n",
    "    tokens = [word.lower() for word in tokens]  # 转换为小写字母\n",
    "    \n",
    "    train_text.append(tokens)\n",
    "    train_text_len.append(len(tokens))\n",
    "\n",
    "plt.hist(train_text_len, bins=80)\n",
    "plt.title('Distribution of Text Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "fig_path = \"../graph/Distribution of Text Length\"\n",
    "plt.savefig(fig_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:57.975688900Z",
     "start_time": "2024-01-23T13:01:56.085409400Z"
    }
   },
   "id": "f23898dbe9c8a16d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "根据训练数据建立词表"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ec0348705a57f7c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, text, min_freq=1, reserved_tokens=None):\n",
    "        self.idx2token = list()\n",
    "        self.token2idx = {}\n",
    "        token_freqs = defaultdict(int)\n",
    "        self.UNK_TOKEN = '<UNK>'\n",
    "        \n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "                \n",
    "        unique_tokens = [self.UNK_TOKEN]\n",
    "        if reserved_tokens:\n",
    "            unique_tokens += reserved_tokens\n",
    "        # 过滤掉出现频率过低的词\n",
    "        unique_tokens += [token for token, freq in token_freqs.items() if freq >= min_freq]\n",
    "\n",
    "        for token in unique_tokens:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = len(self.idx2token) - 1\n",
    "        self.unk = self.token2idx[self.UNK_TOKEN]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token2idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return [self.idx2token[idx] for idx in ids]\n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "reserved_tokens = [PAD_TOKEN]\n",
    "vocab = Vocab(train_text, reserved_tokens=reserved_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.032716800Z",
     "start_time": "2024-01-23T13:01:57.979689700Z"
    }
   },
   "id": "5e6832d88d269167"
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集、验证集、测试集，并转换为Dataloader对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a112833c5f90618"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  3200\n",
      "X_val:  800\n",
      "X_test:  511\n"
     ]
    }
   ],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, text_path):\n",
    "        self.guids = dataframe['guid'].values\n",
    "        self.tags = dataframe['tag'].values\n",
    "        self.text_path = text_path\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}  # 标签映射\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.guids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        guid = self.guids[index]\n",
    "\n",
    "        text_path = self.text_path + str(guid) + '.txt'\n",
    "        with open(text_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = [line.strip() for line in f.readlines() if line.strip()]  # 去除空行\n",
    "        text = ' '.join(text)\n",
    "        \n",
    "        tokens = word_tokenize(text)  # 分词\n",
    "        tokens = [word for word in tokens if word.isalpha()]  # 去除标点符号和数字\n",
    "        tokens = [word.lower() for word in tokens]  # 转换为小写字母     \n",
    "        ids = vocab.convert_tokens_to_ids(tokens)  # 利用词表进行转换\n",
    "        ids = torch.tensor(ids, dtype=torch.long)\n",
    "            \n",
    "        tag = self.tags[index]\n",
    "        if pd.isna(tag):\n",
    "            label = 3\n",
    "        else:\n",
    "            label = self.label_mapping[tag]\n",
    "\n",
    "        return ids, label\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    text = [sample[0] for sample in batch]\n",
    "    padded_text = pad_sequence(text, batch_first=True, padding_value=vocab[PAD_TOKEN])\n",
    "    attention_mask = (padded_text != vocab[PAD_TOKEN]).type(torch.float32)\n",
    "    \n",
    "    labels = torch.tensor([sample[1] for sample in batch], dtype=torch.long)\n",
    "    \n",
    "    return padded_text, attention_mask, labels\n",
    "\n",
    "train_set_path = '../dataset/train.txt'\n",
    "test_set_path = '../dataset/test_without_label.txt'\n",
    "text_path = '../dataset/data/'\n",
    "\n",
    "# 读取训练数据\n",
    "train_df = pd.read_csv(train_set_path, index_col=False)\n",
    "\n",
    "# 将训练数据划分为训练集和验证集，固定划分（8:2）\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 读取测试数据，即测试集\n",
    "test_df = pd.read_csv(test_set_path, index_col=False)\n",
    "\n",
    "num_train = train_df.shape[0]\n",
    "num_val = val_df.shape[0]\n",
    "num_test = test_df.shape[0]\n",
    "\n",
    "print('X_train: ', num_train)\n",
    "print('X_val: ', num_val)\n",
    "print('X_test: ', num_test)\n",
    "print()\n",
    "\n",
    "train_dataset = SentimentDataset(train_df, text_path)\n",
    "val_dataset = SentimentDataset(val_df, text_path)\n",
    "test_dataset = SentimentDataset(test_df, text_path)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.033717200Z",
     "start_time": "2024-01-23T13:01:58.006711100Z"
    }
   },
   "id": "974051affd25fa03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看Dataloader数据格式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "508c612036ee73"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   2, 1851, 1852, 1427, 1853, 1427, 1854, 1855, 1856, 1852, 1853,  178,\n",
      "        1857,   18,   18,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for text, attention_mask, labels in train_loader:\n",
    "    print(text[0])\n",
    "    print(type(text[0]))\n",
    "    print(attention_mask[0])\n",
    "    print(type(attention_mask[0]))\n",
    "    print(labels[0])\n",
    "    print(type(labels[0]))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.100732200Z",
     "start_time": "2024-01-23T13:01:58.022714400Z"
    }
   },
   "id": "600df0bbca2d4e50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练并评价模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f47f047251810ade"
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义文本分类模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b64a3c1f1719ff4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(TextRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, attention_mask):\n",
    "        embedded_text = self.embedding(text)\n",
    "        rnn_output, _ = self.rnn(embedded_text)\n",
    "        output = self.fc(rnn_output[:, -1, :])  # 使用最后一个隐藏层\n",
    "        return output\n",
    "\n",
    "class TextLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(TextLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, attention_mask):\n",
    "        embedded_text = self.embedding(text)\n",
    "        rnn_output, _ = self.rnn(embedded_text)\n",
    "        output = self.fc(rnn_output[:, -1, :])  # 使用最后一个隐藏层\n",
    "        return output\n",
    "    \n",
    "class TextGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(TextGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, attention_mask):\n",
    "        embedded_text = self.embedding(text)\n",
    "        rnn_output, _ = self.rnn(embedded_text)\n",
    "        output = self.fc(rnn_output[:, -1, :])  # 使用最后一个隐藏层\n",
    "        return output\n",
    "\n",
    "class TextBERT(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(TextBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', cache_dir='../model')\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, text, attention_mask):\n",
    "        outputs = self.bert(text, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.fc(pooled_output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88df589b20b6462c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "检查模型准确率"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "565b1b9e91d9bd45"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def check_accuracy(model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, attention_mask, labels in val_loader:\n",
    "            text = text.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            scores = model(text, attention_mask)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.109735300Z",
     "start_time": "2024-01-23T13:01:58.085729700Z"
    }
   },
   "id": "7275dcd4b75d4c05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b67f3e382a83ce"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for text, attention_mask, labels in train_loader:\n",
    "            # 将待更新参数的梯度置为零\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text = text.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            scores = model(text, attention_mask)\n",
    "            \n",
    "            loss = F.cross_entropy(scores, labels)\n",
    "\n",
    "            # 反向传播，计算梯度\n",
    "            loss.backward()\n",
    "\n",
    "            # 利用梯度更新参数\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / num_train\n",
    "        print(f'Epoch: {epoch + 1}/{epochs}')\n",
    "        print(f'Train Loss: {avg_loss}')\n",
    "        train_loss.append(avg_loss)\n",
    "        \n",
    "    val_acc = check_accuracy(model)\n",
    "    \n",
    "    return model, train_loss, val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.123284600Z",
     "start_time": "2024-01-23T13:01:58.104733300Z"
    }
   },
   "id": "dfa663d6a6592205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "记录训练损失"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b848d9a6ea2abfc1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_loss_all = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:01:58.146289600Z",
     "start_time": "2024-01-23T13:01:58.118283300Z"
    }
   },
   "id": "813d3439ab445a4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用RNN作为文本分类模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "494295116ed1cbdd"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Train Loss: 0.0146714954264462\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014276763033121824\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014272417444735765\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014251016974449159\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.01428263982757926\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.014224940687417984\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.014132027141749859\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.014166667461395263\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.01415717639029026\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.014135023914277553\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.014061850253492594\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.014272416327148676\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.01407759377732873\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.01407934719696641\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.014047102872282266\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.014098898600786924\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.014083955008536576\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.013988184053450823\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.013954541068524123\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.013864730540663004\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.01376483565196395\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.013689749408513308\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.013432074896991253\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.013189714290201665\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.01293236032128334\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.012907875813543796\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.012520157787948847\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.012248744256794453\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.011988562401384115\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.011308327931910753\n",
      "model RNN lr 1.000000e-04 val accuracy: 0.573750\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.0151440754160285\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014254276510328054\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.01420235063880682\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014280647449195384\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.014210467152297497\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.014218590427190066\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.014166787061840295\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.014180984180420637\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.014090488217771053\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.013983074240386487\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.013893834203481675\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.013935122080147267\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.013912593293935061\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.013957908973097802\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.013887736555188894\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.013888554275035858\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.01387868493795395\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.013827113807201386\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.014022846892476081\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.013951209485530853\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.013775095157325268\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.013849786389619112\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.014138669930398464\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.013939312044531107\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.013543587923049927\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.01389737255871296\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.013504540622234345\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.013499035630375147\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.013887131121009588\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.013726812936365605\n",
      "model RNN lr 5.000000e-04 val accuracy: 0.602500\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.015197228863835335\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014457396958023309\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014365383069962262\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014211103096604347\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.014254349134862423\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.014152871649712325\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.014203429352492095\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.014095080941915512\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.014034334998577834\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.014081434700638057\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.01398422734811902\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.014020601976662874\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.01414337418973446\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.014029087051749229\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.014114182181656361\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.01413477048277855\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.01412138804793358\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.013914246410131455\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.013906093388795853\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.013956963345408439\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.013838939629495143\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.013828673809766769\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.014028708711266517\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.014032418951392173\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.013815597519278527\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.013898150976747275\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.013727771639823914\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.013704118188470601\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.014076829068362712\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.01425049191340804\n",
      "model RNN lr 1.000000e-03 val accuracy: 0.606250\n",
      "best validation accuracy achieved:\n",
      "model RNN lr 1.000000e-03 val accuracy: 0.606250\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_lr = -1\n",
    "best_val_acc = -1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "num_classes = 3\n",
    "\n",
    "model_type = 'RNN'\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = TextRNN(vocab_size, embed_dim, hidden_dim, num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model, train_loss, val_acc = train_model(model, optimizer, epochs=30)\n",
    "    key = model_type\n",
    "    train_loss_all[key] = train_loss\n",
    "    if val_acc > best_val_acc:\n",
    "        best_model = model\n",
    "        best_val_acc = val_acc\n",
    "        best_lr = lr\n",
    "    print('model %s lr %e val accuracy: %f' % (model_type, lr, val_acc))\n",
    "        \n",
    "print('best validation accuracy achieved:')\n",
    "print('model %s lr %e val accuracy: %f' % (model_type, best_lr, best_val_acc))\n",
    "# model RNN lr 1.000000e-03 val accuracy: 0.606250"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T12:08:18.734652Z",
     "start_time": "2024-01-23T12:04:54.137132900Z"
    }
   },
   "id": "4e07cc1d3c79c9c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用LSTM作为文本分类模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d6921a713fe0e6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Train Loss: 0.014571174941956998\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014296993799507617\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014246158935129642\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014216226413846017\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.014215814806520939\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.014212152678519488\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.014161336310207844\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.014100973643362522\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.01399027768522501\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.01366142312064767\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.012824631202965975\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.011911136489361525\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.010752815399318933\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.009905254524201155\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.008699653297662735\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.007925063939765095\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.007290456527844071\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.006285188067704439\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.005671218484640122\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.005134300664067269\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.004707728056237101\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.004093014970421791\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.0037060517957434058\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.0032929576141759753\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.0031780077458824964\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0031433715554885565\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.00265857164748013\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.002558450383367017\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.0023666172032244504\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.002036708285450004\n",
      "model LSTM lr 1.000000e-04 val accuracy: 0.576250\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.014572749603539705\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014231636561453343\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014228990003466606\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014120955262333154\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.013882712237536907\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.01300739984959364\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.011006189025938511\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.008178249076008797\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.005365875288844108\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.004064267301000655\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.002889861210715026\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.00195062771148514\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.0015563574177213013\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.0016931805852800608\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.0014623386680614203\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.001069072958198376\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.0009719450291595422\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.0008973879998666234\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.0008303661241006921\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.000806230880698422\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.0007980261415650602\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.0007629942092353304\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.0006896523575778701\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.0007153073597692128\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.0006629362376588688\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0006700898854614934\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.0006612747671260877\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.0006491912711044279\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.0006580583827599185\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.0006299176607353729\n",
      "model LSTM lr 5.000000e-04 val accuracy: 0.570000\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.014475230704993009\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014239607732743026\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.01414920337498188\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.013545575626194477\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.011528528574854136\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.008607717081904411\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.005712252170778811\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.003678716975264251\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.0024023092293646185\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.0018078406783752143\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.0013222552023944446\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.0009748722371296026\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.0008564233884317218\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.0008393281415919774\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.0007599378503073239\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.0007389295586835942\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.0007036936857912223\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.0007016799693883514\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.000670878866694693\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.0006620064242815715\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.0006417737602714624\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.0006386081285018008\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.0006298690485709812\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.000633353067059943\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.0006336118658146006\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0006071988721669186\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.0006065464772291307\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.0005897475911751826\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.0006153064729915059\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.0006146585735041298\n",
      "model LSTM lr 1.000000e-03 val accuracy: 0.590000\n",
      "best validation accuracy achieved:\n",
      "model LSTM lr 1.000000e-03 val accuracy: 0.590000\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_lr = -1\n",
    "best_val_acc = -1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "num_classes = 3\n",
    "\n",
    "model_type = 'LSTM'\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = TextLSTM(vocab_size, embed_dim, hidden_dim, num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model, train_loss, val_acc = train_model(model, optimizer, epochs=30)\n",
    "    key = model_type\n",
    "    train_loss_all[key] = train_loss\n",
    "    if val_acc > best_val_acc:\n",
    "        best_model = model\n",
    "        best_val_acc = val_acc\n",
    "        best_lr = lr\n",
    "    print('model %s lr %e val accuracy: %f' % (model_type, lr, val_acc))\n",
    "        \n",
    "print('best validation accuracy achieved:')\n",
    "print('model %s lr %e val accuracy: %f' % (model_type, best_lr, best_val_acc))\n",
    "# model LSTM lr 1.000000e-03 val accuracy: 0.590000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T12:12:36.241505100Z",
     "start_time": "2024-01-23T12:09:16.665673700Z"
    }
   },
   "id": "e1b857921cf3810d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用GRU作为文本分类模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62bd48ed063f4cac"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Train Loss: 0.014619244784116745\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014237936660647392\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014149579908698797\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.014101049210876227\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.014030108116567136\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.013919027782976627\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.013670093081891536\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.012987087070941926\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.01187818368896842\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.010693232947960495\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.009303506640717387\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.007641985435038805\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.006275113713927567\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.005153908981010318\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.004122237239498645\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.0035290223965421317\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.0027675224468111993\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.002218010815558955\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.0017627011012518777\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.0017910578835289926\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.001532632971648127\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.0013653292678645812\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.001419531018473208\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.0012753853481262923\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.0011718893074430525\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0011668620540876873\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.0011843940184917301\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.001342299894313328\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.001103694340272341\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.0010943147115176544\n",
      "model GRU lr 1.000000e-04 val accuracy: 0.577500\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.01467879867181182\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.014086991567164659\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.013119241688400507\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.010934373829513788\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.008052627630531788\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.004903721241280436\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.0031103850016370414\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.0017221773939672857\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.001531716957106255\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.0012555434356909246\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.0011845109406567645\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.0011147256899857894\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.0009342408983502537\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.0009127971953421366\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.0008209849801642121\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.0009023319200059632\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.0008354139218863566\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.000758275374682853\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.0007489348876697477\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.0007628087591729127\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.0007247376933082705\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.0007553082131198607\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.0006985049955619615\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.0007226705791981658\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.000683413683091203\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0006635990009453963\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.000678500786452787\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.000652328157593729\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.00067291483952431\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.0006245760439196602\n",
      "model GRU lr 5.000000e-04 val accuracy: 0.592500\n",
      "Epoch: 1/30\n",
      "Train Loss: 0.014882945381104946\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.013559604082256555\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.010781622035428881\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.006675778245553374\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.003392391868401319\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.0018821550032589584\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.0013870137190679088\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.001075447515322594\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.0009326369511836675\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.0008669816563633503\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.0007906648559583118\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.0007457794857327827\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.0007430147729792225\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.0006946002494623827\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.0006719832476665033\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.0006937615442438982\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.0006764412960365007\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.000688644948277215\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.000655004641157575\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.0006510907943993515\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.0006435583335951379\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.0006472929825622486\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.000612435257571633\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.0018355451240222465\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.0019796578655950723\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.0009822755193454214\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.0007377940929654869\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.0006697234812600072\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.0006807279944041511\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.0006641408965879236\n",
      "model GRU lr 1.000000e-03 val accuracy: 0.585000\n",
      "best validation accuracy achieved:\n",
      "model GRU lr 5.000000e-04 val accuracy: 0.592500\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_lr = -1\n",
    "best_val_acc = -1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "num_classes = 3\n",
    "\n",
    "model_type = 'GRU'\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = TextGRU(vocab_size, embed_dim, hidden_dim, num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model, train_loss, val_acc = train_model(model, optimizer, epochs=30)\n",
    "    key = model_type\n",
    "    train_loss_all[key] = train_loss\n",
    "    if val_acc > best_val_acc:\n",
    "        best_model = model\n",
    "        best_val_acc = val_acc\n",
    "        best_lr = lr\n",
    "    print('model %s lr %e val accuracy: %f' % (model_type, lr, val_acc))\n",
    "        \n",
    "print('best validation accuracy achieved:')\n",
    "print('model %s lr %e val accuracy: %f' % (model_type, best_lr, best_val_acc))\n",
    "# model GRU lr 5.000000e-04 val accuracy: 0.592500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T12:15:59.586355100Z",
     "start_time": "2024-01-23T12:12:40.912356600Z"
    }
   },
   "id": "cc42fb5708799552"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用BERT作为文本分类模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41055e09947e8037"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n",
      "Train Loss: 0.0154995197057724\n",
      "Epoch: 2/30\n",
      "Train Loss: 0.015183483455330134\n",
      "Epoch: 3/30\n",
      "Train Loss: 0.014386502895504236\n",
      "Epoch: 4/30\n",
      "Train Loss: 0.01460214564576745\n",
      "Epoch: 5/30\n",
      "Train Loss: 0.014478271417319775\n",
      "Epoch: 6/30\n",
      "Train Loss: 0.014343866854906082\n",
      "Epoch: 7/30\n",
      "Train Loss: 0.014417120162397623\n",
      "Epoch: 8/30\n",
      "Train Loss: 0.014625435639172792\n",
      "Epoch: 9/30\n",
      "Train Loss: 0.014489972479641438\n",
      "Epoch: 10/30\n",
      "Train Loss: 0.014563502985984087\n",
      "Epoch: 11/30\n",
      "Train Loss: 0.014381342455744744\n",
      "Epoch: 12/30\n",
      "Train Loss: 0.014743026047945022\n",
      "Epoch: 13/30\n",
      "Train Loss: 0.014407029636204242\n",
      "Epoch: 14/30\n",
      "Train Loss: 0.014418645072728395\n",
      "Epoch: 15/30\n",
      "Train Loss: 0.014369881339371204\n",
      "Epoch: 16/30\n",
      "Train Loss: 0.01440983396023512\n",
      "Epoch: 17/30\n",
      "Train Loss: 0.014436202812939882\n",
      "Epoch: 18/30\n",
      "Train Loss: 0.014369498584419488\n",
      "Epoch: 19/30\n",
      "Train Loss: 0.014579063132405281\n",
      "Epoch: 20/30\n",
      "Train Loss: 0.014493127577006817\n",
      "Epoch: 21/30\n",
      "Train Loss: 0.014560477789491415\n",
      "Epoch: 22/30\n",
      "Train Loss: 0.01444564811885357\n",
      "Epoch: 23/30\n",
      "Train Loss: 0.01455049691721797\n",
      "Epoch: 24/30\n",
      "Train Loss: 0.014498310089111328\n",
      "Epoch: 25/30\n",
      "Train Loss: 0.014476096760481595\n",
      "Epoch: 26/30\n",
      "Train Loss: 0.01432379089295864\n",
      "Epoch: 27/30\n",
      "Train Loss: 0.014431180357933044\n",
      "Epoch: 28/30\n",
      "Train Loss: 0.014334459975361823\n",
      "Epoch: 29/30\n",
      "Train Loss: 0.014593953471630812\n",
      "Epoch: 30/30\n",
      "Train Loss: 0.014416459873318672\n",
      "model BERT lr 1.000000e-03 val accuracy: 0.603750\n",
      "best validation accuracy achieved:\n",
      "model BERT lr 1.000000e-03 val accuracy: 0.603750\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_lr = -1\n",
    "best_val_acc = -1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "num_classes = 3\n",
    "\n",
    "model_type = 'BERT'\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = TextBERT(num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model, train_loss, val_acc = train_model(model, optimizer, epochs=30)\n",
    "    key = model_type\n",
    "    train_loss_all[key] = train_loss\n",
    "    if val_acc > best_val_acc:\n",
    "        # best_model = model\n",
    "        best_val_acc = val_acc\n",
    "        best_lr = lr\n",
    "    print('model %s lr %e val accuracy: %f' % (model_type, lr, val_acc))\n",
    "        \n",
    "print('best validation accuracy achieved:')\n",
    "print('model %s lr %e val accuracy: %f' % (model_type, best_lr, best_val_acc))\n",
    "# model BERT lr 1.000000e-03 val accuracy: 0.603750"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:11:44.456839800Z",
     "start_time": "2024-01-23T13:02:20.063825400Z"
    }
   },
   "id": "8b2b4b2c7680bd2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "预测测试集的标签并补全保存"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb577d2a7274b42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    all_preds = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, attention_mask, labels in test_loader:\n",
    "            text = text.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            scores = model(text, attention_mask)\n",
    "            _, preds = scores.max(1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            \n",
    "    tag = np.concatenate(all_preds)\n",
    "    label_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}  # 标签映射\n",
    "    tag_mapping = []\n",
    "    for i in range(len(tag)):\n",
    "        tag_mapping.append(label_mapping[tag[i]])\n",
    "    \n",
    "    test_df = pd.read_csv(test_set_path, index_col=False)\n",
    "    test_df['tag'] = tag_mapping\n",
    "    result_path = '../result/result_text_model.txt'\n",
    "    test_df.to_csv(result_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bbb5bdefac8bc36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict(best_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5d80742b73d7020"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
